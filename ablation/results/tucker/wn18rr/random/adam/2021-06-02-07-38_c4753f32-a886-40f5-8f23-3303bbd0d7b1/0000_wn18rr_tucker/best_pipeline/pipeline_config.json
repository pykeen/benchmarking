{
  "metadata": {
    "_stopper_comment": "While the original config had 1000, early stopping will now switch it to 551",
    "_stopper_kwargs_removed_comment": "stopper_kwargs config removed after HPO: {'frequency': 50, 'patience': 2, 'delta': 0.002}",
    "best_trial_evaluation": 0.5100920679886686,
    "best_trial_number": 7,
    "git_hash": "4ac32f00",
    "version": "0.1.2-dev"
  },
  "pipeline": {
    "dataset": "wn18rr",
    "dataset_kwargs": {
      "create_inverse_triples": false
    },
    "evaluation_kwargs": {
      "batch_size": 32
    },
    "evaluator": "rankbased",
    "evaluator_kwargs": {
      "filtered": true
    },
    "filter_validation_when_testing": true,
    "loss": "crossentropy",
    "model": "tucker",
    "model_kwargs": {
      "apply_batch_normalization": true,
      "automatic_memory_optimization": true,
      "dropout_0": 0.24225988050489122,
      "dropout_1": 0.323320989986829,
      "dropout_2": 0.17307159169702102,
      "embedding_dim": 128,
      "relation_dim": 64
    },
    "optimizer": "adam",
    "optimizer_kwargs": {
      "lr": 0.026590461508453893,
      "weight_decay": 0.0
    },
    "regularizer": "no",
    "training_kwargs": {
      "batch_size": 128,
      "label_smoothing": 0.006914205272663172,
      "num_epochs": 551
    },
    "training_loop": "lcwa"
  }
}