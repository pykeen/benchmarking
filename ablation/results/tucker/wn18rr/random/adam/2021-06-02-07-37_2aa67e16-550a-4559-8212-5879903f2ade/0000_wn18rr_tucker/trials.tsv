number	value	datetime_start	datetime_complete	params_model.dropout_0	params_model.dropout_1	params_model.dropout_2	params_model.embedding_dim	params_model.relation_dim	params_optimizer.lr	params_training.batch_size	params_training.label_smoothing	user_attrs_both.optimistic.arithmetic_mean_rank	user_attrs_both.optimistic.geometric_mean_rank	user_attrs_both.optimistic.harmonic_mean_rank	user_attrs_both.optimistic.hits_at_1	user_attrs_both.optimistic.hits_at_10	user_attrs_both.optimistic.hits_at_3	user_attrs_both.optimistic.hits_at_5	user_attrs_both.optimistic.inverse_arithmetic_mean_rank	user_attrs_both.optimistic.inverse_geometric_mean_rank	user_attrs_both.optimistic.inverse_harmonic_mean_rank	user_attrs_both.optimistic.inverse_median_rank	user_attrs_both.optimistic.median_rank	user_attrs_both.optimistic.rank_std	user_attrs_both.optimistic.rank_var	user_attrs_both.pessimistic.arithmetic_mean_rank	user_attrs_both.pessimistic.geometric_mean_rank	user_attrs_both.pessimistic.harmonic_mean_rank	user_attrs_both.pessimistic.hits_at_1	user_attrs_both.pessimistic.hits_at_10	user_attrs_both.pessimistic.hits_at_3	user_attrs_both.pessimistic.hits_at_5	user_attrs_both.pessimistic.inverse_arithmetic_mean_rank	user_attrs_both.pessimistic.inverse_geometric_mean_rank	user_attrs_both.pessimistic.inverse_harmonic_mean_rank	user_attrs_both.pessimistic.inverse_median_rank	user_attrs_both.pessimistic.median_rank	user_attrs_both.pessimistic.rank_std	user_attrs_both.pessimistic.rank_var	user_attrs_both.realistic.adjusted_arithmetic_mean_rank	user_attrs_both.realistic.adjusted_arithmetic_mean_rank_index	user_attrs_both.realistic.arithmetic_mean_rank	user_attrs_both.realistic.geometric_mean_rank	user_attrs_both.realistic.harmonic_mean_rank	user_attrs_both.realistic.hits_at_1	user_attrs_both.realistic.hits_at_10	user_attrs_both.realistic.hits_at_3	user_attrs_both.realistic.hits_at_5	user_attrs_both.realistic.inverse_arithmetic_mean_rank	user_attrs_both.realistic.inverse_geometric_mean_rank	user_attrs_both.realistic.inverse_harmonic_mean_rank	user_attrs_both.realistic.inverse_median_rank	user_attrs_both.realistic.median_rank	user_attrs_both.realistic.rank_std	user_attrs_both.realistic.rank_var	user_attrs_failure	user_attrs_head.optimistic.arithmetic_mean_rank	user_attrs_head.optimistic.geometric_mean_rank	user_attrs_head.optimistic.harmonic_mean_rank	user_attrs_head.optimistic.hits_at_1	user_attrs_head.optimistic.hits_at_10	user_attrs_head.optimistic.hits_at_3	user_attrs_head.optimistic.hits_at_5	user_attrs_head.optimistic.inverse_arithmetic_mean_rank	user_attrs_head.optimistic.inverse_geometric_mean_rank	user_attrs_head.optimistic.inverse_harmonic_mean_rank	user_attrs_head.optimistic.inverse_median_rank	user_attrs_head.optimistic.median_rank	user_attrs_head.optimistic.rank_std	user_attrs_head.optimistic.rank_var	user_attrs_head.pessimistic.arithmetic_mean_rank	user_attrs_head.pessimistic.geometric_mean_rank	user_attrs_head.pessimistic.harmonic_mean_rank	user_attrs_head.pessimistic.hits_at_1	user_attrs_head.pessimistic.hits_at_10	user_attrs_head.pessimistic.hits_at_3	user_attrs_head.pessimistic.hits_at_5	user_attrs_head.pessimistic.inverse_arithmetic_mean_rank	user_attrs_head.pessimistic.inverse_geometric_mean_rank	user_attrs_head.pessimistic.inverse_harmonic_mean_rank	user_attrs_head.pessimistic.inverse_median_rank	user_attrs_head.pessimistic.median_rank	user_attrs_head.pessimistic.rank_std	user_attrs_head.pessimistic.rank_var	user_attrs_head.realistic.adjusted_arithmetic_mean_rank	user_attrs_head.realistic.adjusted_arithmetic_mean_rank_index	user_attrs_head.realistic.arithmetic_mean_rank	user_attrs_head.realistic.geometric_mean_rank	user_attrs_head.realistic.harmonic_mean_rank	user_attrs_head.realistic.hits_at_1	user_attrs_head.realistic.hits_at_10	user_attrs_head.realistic.hits_at_3	user_attrs_head.realistic.hits_at_5	user_attrs_head.realistic.inverse_arithmetic_mean_rank	user_attrs_head.realistic.inverse_geometric_mean_rank	user_attrs_head.realistic.inverse_harmonic_mean_rank	user_attrs_head.realistic.inverse_median_rank	user_attrs_head.realistic.median_rank	user_attrs_head.realistic.rank_std	user_attrs_head.realistic.rank_var	user_attrs_random_seed	user_attrs_stopped_epoch	user_attrs_tail.optimistic.arithmetic_mean_rank	user_attrs_tail.optimistic.geometric_mean_rank	user_attrs_tail.optimistic.harmonic_mean_rank	user_attrs_tail.optimistic.hits_at_1	user_attrs_tail.optimistic.hits_at_10	user_attrs_tail.optimistic.hits_at_3	user_attrs_tail.optimistic.hits_at_5	user_attrs_tail.optimistic.inverse_arithmetic_mean_rank	user_attrs_tail.optimistic.inverse_geometric_mean_rank	user_attrs_tail.optimistic.inverse_harmonic_mean_rank	user_attrs_tail.optimistic.inverse_median_rank	user_attrs_tail.optimistic.median_rank	user_attrs_tail.optimistic.rank_std	user_attrs_tail.optimistic.rank_var	user_attrs_tail.pessimistic.arithmetic_mean_rank	user_attrs_tail.pessimistic.geometric_mean_rank	user_attrs_tail.pessimistic.harmonic_mean_rank	user_attrs_tail.pessimistic.hits_at_1	user_attrs_tail.pessimistic.hits_at_10	user_attrs_tail.pessimistic.hits_at_3	user_attrs_tail.pessimistic.hits_at_5	user_attrs_tail.pessimistic.inverse_arithmetic_mean_rank	user_attrs_tail.pessimistic.inverse_geometric_mean_rank	user_attrs_tail.pessimistic.inverse_harmonic_mean_rank	user_attrs_tail.pessimistic.inverse_median_rank	user_attrs_tail.pessimistic.median_rank	user_attrs_tail.pessimistic.rank_std	user_attrs_tail.pessimistic.rank_var	user_attrs_tail.realistic.adjusted_arithmetic_mean_rank	user_attrs_tail.realistic.adjusted_arithmetic_mean_rank_index	user_attrs_tail.realistic.arithmetic_mean_rank	user_attrs_tail.realistic.geometric_mean_rank	user_attrs_tail.realistic.harmonic_mean_rank	user_attrs_tail.realistic.hits_at_1	user_attrs_tail.realistic.hits_at_10	user_attrs_tail.realistic.hits_at_3	user_attrs_tail.realistic.hits_at_5	user_attrs_tail.realistic.inverse_arithmetic_mean_rank	user_attrs_tail.realistic.inverse_geometric_mean_rank	user_attrs_tail.realistic.inverse_harmonic_mean_rank	user_attrs_tail.realistic.inverse_median_rank	user_attrs_tail.realistic.median_rank	user_attrs_tail.realistic.rank_std	user_attrs_tail.realistic.rank_var	system_attrs__number	system_attrs_fail_reason	state
0	0.000708215297450425	2021-06-02 07:37:59.252072	2021-06-02 10:36:12.209601	0.19238246181434784	0.3105437091330763	0.31729970492579906	128	128	0.0675304462823211	128	0.0024660598413106913	19957.30435552408	14271.086545413715	2968.568846125031	0.0	0.000708215297450425	0.0	0.00017705382436260624	5.010696746342925e-05	7.007174939467865e-05	0.0003368626607078129	5.258452963138245e-05	19017.0	12170.28717931007	148115890.02687904	19957.38544617564	14271.175599898634	2968.589197843494	0.0	0.000708215297450425	0.0	0.00017705382436260624	5.010676386929363e-05	7.007131213542792e-05	0.00033686035128283883	5.258452963138245e-05	19017.0	12170.290038131037	148115959.61223155	0.9844147632655607	0.015586005528786528	19957.344900849857	14271.131077004144	2968.5790326251185	0.0	0.000708215297450425	0.0	0.00017705382436260624	5.0106865666154635e-05	7.007153074302253e-05	0.00033686150478388937	5.258452963138245e-05	19017.0	12170.288607660701	148115924.79375586		20553.856232294616	14710.842482681614	3121.296949554193	0.0	0.000708215297450425	0.0	0.0	4.865267075424906e-05	6.797707209340684e-05	0.00032037964223263906	4.872700694359849e-05	20522.5	12309.45927609498	151522787.66984075	20554.015934844192	14711.023934393199	3121.3418312557155	0.0	0.000708215297450425	0.0	0.0	4.865229272809652e-05	6.797623363674094e-05	0.00032037503550122226	4.872700694359849e-05	20522.5	12309.456551570465	151522720.59500104	1.0140391617126163	-0.014039854376157956	20553.936083569406	14710.933217342477	3121.319413845664	0.0	0.000708215297450425	0.0	0.0	4.8652481740438476e-05	6.79766528218017e-05	0.0003203773364443777	4.872700694359849e-05	20522.5	12309.457911887515	151522754.08453014	2713371686.0	101.0	19360.75247875354	13844.476373562718	2830.089792840317	0.0	0.000708215297450425	0.0	0.0003541076487252125	5.16508850106626e-05	7.223097306226696e-05	0.00035334567918298673	5.5390921427977955e-05	18053.5	11999.885170307274	143997244.10056043	19360.75495750708	13844.478393307907	2830.089889902585	0.0	0.000708215297450425	0.0	0.0003541076487252125	5.165087839781024e-05	7.223096252462472e-05	0.00035334566706445535	5.5390921427977955e-05	18053.5	11999.885947351511	143997262.74944428	0.9548018717479025	0.04520035736912709	19360.753718130312	13844.477383456266	2830.089841374013	0.0	0.000708215297450425	0.0	0.0003541076487252125	5.16508817042362e-05	7.223096779333613e-05	0.0003533456731234011	5.5390921427977955e-05	18053.5	11999.88555880364	143997253.42438418	0		COMPLETE
1		2021-06-02 10:36:12.272111	2021-06-02 10:37:33.884718	0.431765008356483	0.48802431664254653	0.3420430222088682	256	64	0.004974369285468511	256	0.38051486301335097																																													"CUDA out of memory. Tried to allocate 9.90 GiB (GPU 0; 31.75 GiB total capacity; 14.29 GiB already allocated; 6.37 GiB free; 24.30 GiB reserved in total by PyTorch)
Exception raised from malloc at ../c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xd4 (0x2000c1c5bb94 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x20ce0 (0x2000c1be0ce0 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x22120 (0x2000c1be2120 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x227b8 (0x2000c1be27b8 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x4f8 (0x20004eef5068 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x27b1b50 (0x20004f0c1b50 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x27d22e8 (0x20004f0e22e8 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf3344c (0x20004921344c in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0xf36278 (0x200049216278 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x19c (0x20004935a37c in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x214 (0x20004900c6e4 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x268 (0x200049010b08 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xb4 (0x200049010fd4 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x168 (0x2000490111e8 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x54 (0x200048d404f4 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2793dd0 (0x20004f0a3dd0 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0x8ba634 (0x200048b9a634 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xf0 (0x2000493c7800 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x9c (0x2000492f555c in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0x2626560 (0x20004a906560 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #20: <unknown function> + 0x8ba634 (0x200048b9a634 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #21: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xf0 (0x2000493c7800 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #22: at::Tensor::mul(at::Tensor const&) const + 0x9c (0x20004950625c in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #23: torch::autograd::generated::MulBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x290 (0x20004a61cf50 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2b33698 (0x20004ae13698 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #25: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1418 (0x20004ae0c708 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #26: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x510 (0x20004ae0d2a0 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0xe4 (0x20004ae04fa4 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #28: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x80 (0x200047652ef0 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_python.so)
frame #29: std::thread::_State_impl<std::thread::_Invoker<std::tuple<void (torch::autograd::Engine::*)(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool), torch::autograd::Engine*, int, std::shared_ptr<torch::autograd::ReadyQueue>, bool> > >::_M_run() + 0x58 (0x20004ae0e768 in /sw/installed/PyTorch/1.6.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)
frame #30: <unknown function> + 0xfc814 (0x2000451fc814 in /sw/installed/GCCcore/8.3.0/lib64/libstdc++.so.6)
frame #31: <unknown function> + 0x8b94 (0x200000708b94 in /lib64/libpthread.so.0)
frame #32: clone + 0xe4 (0x2000008985f4 in /lib64/libc.so.6)
"																																																																																											1	Setting status of trial#1 as TrialState.FAIL because the returned value from the objective function cannot be casted to float. Returned value is: None	FAIL
2	0.0017705382436260624	2021-06-02 10:37:33.895256	2021-06-02 13:27:02.115852	0.3086820304850169	0.11539652573291836	0.47272727787998725	128	64	0.0740237153631449	512	0.01878698482199752	21917.269652974504	14305.216538645398	695.3827558276673	0.000708215297450425	0.0017705382436260624	0.0010623229461756375	0.0012393767705382436	4.562612112883709e-05	6.990456923867668e-05	0.0014380569429130684	4.25396150164841e-05	23507.5	13103.229213448481	171694615.82016972	21917.311260623228	14305.257071598753	695.3829794242475	0.000708215297450425	0.0017705382436260624	0.0010623229461756375	0.0012393767705382436	4.562603451257299e-05	6.990437116893001e-05	0.0014380564805137517	4.25396150164841e-05	23507.5	13103.22907053292	171694612.07485902	1.0810909168350051	-0.08109491691787363	21917.290456798866	14305.236805995091	695.3828676494247	0.000708215297450425	0.0017705382436260624	0.0010623229461756375	0.0012393767705382436	4.5626077820663935e-05	6.990447019939693e-05	0.0014380567116648423	4.25396150164841e-05	23507.5	13103.229141535978	171694613.93559766		23901.890934844192	17957.140187669294	566.776980530432	0.0010623229461756375	0.0028328611898017	0.0017705382436260624	0.002124645892351275	4.183769404378795e-05	5.56881546587621e-05	0.0017643624112329435	3.921261077562544e-05	25502.0	12175.716201898815	148248065.0291813	23901.965297450424	17957.233001882556	566.7772617540345	0.0010623229461756375	0.0028328611898017	0.0017705382436260624	0.002124645892351275	4.183756388043405e-05	5.568786682754322e-05	0.001764361535791413	3.921261077562544e-05	25502.0	12175.701985343852	148247718.8359062	1.1792140956197883	-0.17922293767693698	23901.928116147308	17957.18659683301	566.777121172766	0.0010623229461756375	0.0028328611898017	0.0017705382436260624	0.002124645892351275	4.183762896200976e-05	5.5688010736401405e-05	0.001764361973417022	3.921261077562544e-05	25502.0	12175.70909275679	148247891.91144037	2439135062.0	101.0	19932.648371104817	11395.980544722459	899.4816043449953	0.0003541076487252125	0.000708215297450425	0.0003541076487252125	0.0003541076487252125	5.016894801845002e-05	8.775023755749614e-05	0.0011117514745931935	4.8509544252831746e-05	20614.5	13684.433614375788	187263723.34625798	19932.657223796035	11395.986222547344	899.481644278208	0.0003541076487252125	0.000708215297450425	0.0003541076487252125	0.0003541076487252125	5.0168925736914715e-05	8.775019383767472e-05	0.0011117514252360905	4.8509544252831746e-05	20614.5	13684.43648902003	187263802.02202287	0.983005851785849	0.016994986344990748	19932.652797450424	11395.983383704863	899.4816243132027	0.0003541076487252125	0.000708215297450425	0.0003541076487252125	0.0003541076487252125	5.01689368776799e-05	8.775021569704127e-05	0.0011117514499126627	4.8509544252831746e-05	20614.5	13684.435051617837	187263762.68194684	2		COMPLETE
3		2021-06-02 13:27:02.184877	2021-06-02 13:27:10.042696	0.4403515466798583	0.33451536230522755	0.3161533880357628	256	256	0.019710399218979064	512	0.08209743894226378																																													The current model can't be trained on this hardware with these parameters.																																																																																											3	Setting status of trial#3 as TrialState.FAIL because the returned value from the objective function cannot be casted to float. Returned value is: None	FAIL
4	0.0033640226628895184	2021-06-02 13:27:10.052125	2021-06-02 16:00:53.403293	0.22535539042538258	0.4188644329176401	0.4772303418092677	64	128	0.07455548193132013	256	0.020015456804674866	19736.044794617563	11719.911759551575	270.7644024207525	0.0030099150141643057	0.0033640226628895184	0.0033640226628895184	0.0033640226628895184	5.0668713534371444e-05	8.532487449702965e-05	0.003693247676059192	4.9531923324582696e-05	20189.0	13184.614178156797	173834051.02685323	19736.13137393768	11719.977172482028	270.76445624726597	0.0030099150141643057	0.0033640226628895184	0.0033640226628895184	0.0033640226628895184	5.0668491258653586e-05	8.532439827169241e-05	0.0036932469418614745	4.9531923324582696e-05	20189.0	13184.62340792229	173834294.40873238	0.9735010631822607	0.026500243967138237	19736.08808427762	11719.94446721969	270.7644293394903	0.0030099150141643057	0.0033640226628895184	0.0033640226628895184	0.0033640226628895184	5.066860239626874e-05	8.532463637493915e-05	0.003693247308885535	4.9531923324582696e-05	20189.0	13184.618791961577	173834172.68934634		22016.85587818697	15798.158252111587	154.79232439849528	0.0060198300283286115	0.006373937677053824	0.006373937677053824	0.006373937677053824	4.541974592252032e-05	6.329851771590779e-05	0.006460268646303246	4.30070531567177e-05	23252.0	11888.415629302772	141334426.17505044	22017.022662889518	15798.320644943467	154.79234925786648	0.0060198300283286115	0.006373937677053824	0.006373937677053824	0.006373937677053824	4.5419401856070935e-05	6.329786706285568e-05	0.006460267608795791	4.30070531567177e-05	23252.0	11888.405763095963	141334191.5880133	1.086217187335781	-0.08622144111556884	22016.939270538245	15798.239450833918	154.7923368295209	0.0060198300283286115	0.006373937677053824	0.006373937677053824	0.006373937677053824	4.541957388864402e-05	6.329819237846876e-05	0.00646026812749355	4.30070531567177e-05	23252.0	11888.41069400947	141334308.82943872	149229840.0	101.0	17455.23371104816	8694.452192445688	1079.6492842645214	0.0	0.0003541076487252125	0.0003541076487252125	0.0003541076487252125	5.7289407667286484e-05	0.00011501587194520039	0.0009262267058151388	6.575702778234424e-05	15207.5	13997.481111999756	195929477.48078993	17455.240084985835	8694.459873965377	1079.649786526131	0.0	0.0003541076487252125	0.0003541076487252125	0.0003541076487252125	5.728938674754478e-05	0.00011501577032914858	0.0009262262749271582	6.575702778234424e-05	15207.5	13997.480740669684	195929467.0854187	0.8608287210648512	0.13917814269433326	17455.236898016996	8694.456033672976	1079.6495355044071	0.0	0.0003541076487252125	0.0003541076487252125	0.0003541076487252125	5.728939720741373e-05	0.0001150158211309684	0.0009262264902775184	6.575702778234424e-05	15207.5	13997.480926278164	195929472.281521	4		COMPLETE
5	0.006373937677053824	2021-06-02 16:00:53.464222	2021-06-02 18:34:18.070774	0.23282724029007118	0.3367371004594657	0.42681817450707493	64	256	0.06667201705880364	512	0.0052775188229739235	20090.242209631728	12251.175761711787	223.24912327353914	0.002478753541076487	0.006373937677053824	0.005488668555240793	0.005842776203966006	4.9775407860467544e-05	8.162481866640657e-05	0.004479300905360044	4.877810838495683e-05	20501.0	12916.939822165721	166847334.36945063	20090.3132082153	12251.235670023165	223.2491661291392	0.002478753541076487	0.006373937677053824	0.005488668555240793	0.005842776203966006	4.977523195562136e-05	8.162441952258266e-05	0.004479300045499596	4.877810838495683e-05	20501.0	12916.945985688373	166847493.59719098	0.99097179875501	0.009028646591454748	20090.277708923513	12251.205717239567	223.2491447075065	0.002478753541076487	0.006373937677053824	0.005488668555240793	0.005842776203966006	4.977531990788904e-05	8.1624619084865e-05	0.004479300475306036	4.877810838495683e-05	20501.0	12916.942903145204	166847413.96311325		22409.427407932013	17053.869539848612	813.5887637040747	0.0003541076487252125	0.002478753541076487	0.0017705382436260624	0.002124645892351275	4.462407636734356e-05	5.863771841712336e-05	0.0012291221863085222	4.285132731986373e-05	23336.5	11548.063963186492	133357781.29784653	22409.56480169972	17054.030533778794	813.5898741594592	0.0003541076487252125	0.002478753541076487	0.0017705382436260624	0.002124645892351275	4.462380277568586e-05	5.8637164863714024e-05	0.0012291205086999465	4.285132731986373e-05	23336.5	11548.049843213923	133357455.18135312	1.1055841835907538	-0.10558939289854896	22409.496104815866	17053.950040455857	813.5893190940883	0.0003541076487252125	0.002478753541076487	0.0017705382436260624	0.002124645892351275	4.462393957109536e-05	5.863744162658927e-05	0.0012291213472584368	4.285132731986373e-05	23336.5	11548.056901597532	133357618.2025344	3671851309.0	101.0	17771.057011331446	8801.011828643717	129.37481545869636	0.004603399433427762	0.010269121813031162	0.009206798866855524	0.009560906515580737	5.6271272967182824e-05	0.00011362329916946667	0.007729479624411566	6.231500233681259e-05	16047.5	13768.79252051626	189579647.4730245	17771.06161473088	8801.014818471243	129.3748161635658	0.004603399433427762	0.010269121813031162	0.009206798866855524	0.009560906515580737	5.6271258390724104e-05	0.00011362326057004667	0.007729479582299243	6.231500233681259e-05	16047.5	13768.79356026768	189579676.10526878	0.8764039325150689	0.12360216309352112	17771.05931303116	8801.01332360369	129.3748158111607	0.004603399433427762	0.010269121813031162	0.009206798866855524	0.009560906515580737	5.627126567895252e-05	0.0001136232798691568	0.007729479603353636	6.231500233681259e-05	16047.5	13768.793040350381	189579661.7880011	5		COMPLETE
6		2021-06-02 18:34:18.129658	2021-06-02 18:34:24.186426	0.13210805624446295	0.33399645709687	0.3509108302687264	256	256	0.00373510196120188	256	0.01372177838575144																																													The current model can't be trained on this hardware with these parameters.																																																																																											6	Setting status of trial#6 as TrialState.FAIL because the returned value from the objective function cannot be casted to float. Returned value is: None	FAIL
7	0.5286827195467422	2021-06-02 18:34:24.196069	2021-06-03 10:28:17.036672	0.42171031856276375	0.302115686772603	0.4198516881474931	128	256	0.003403167908140656	256	0.11937695777161776	3682.4948654390937	34.19489523480406	2.1541015786267317	0.425814447592068	0.5286827195467422	0.48441926345609065	0.50407223796034	0.000271555029006337	0.029244131123472066	0.46423066113600514	0.2	5.0	8270.380134407862	68399187.5676082	3682.4962818696886	34.19490473233962	2.1541015793256135	0.425814447592068	0.5286827195467422	0.48441926345609065	0.50407223796034	0.0002715549245557627	0.029244123000999506	0.464230660985389	0.2	5.0	8270.38246423961	68399226.10480204	0.18164254946614125	0.8183978187741747	3682.495573654391	34.19489998421531	2.1541015789762845	0.425814447592068	0.5286827195467422	0.48441926345609065	0.50407223796034	0.0002715549767810398	0.029244127061684912	0.46423066106067296	0.2	5.0	8270.381299302438	68399206.8358515		4146.069050991501	44.16259632360943	2.241712324637226	0.4086402266288952	0.5145184135977338	0.46458923512747874	0.4868980169971671	0.00024119231679483425	0.022643596238597904	0.4460875684224241	0.14285714285714285	7.0	8488.034244483784	72046725.33552942	4146.071175637394	44.16261081751634	2.241712325496209	0.4086402266288952	0.5145184135977338	0.46458923512747874	0.4868980169971671	0.00024119219319631327	0.02264358880710393	0.4460875682514916	0.14285714285714285	7.0	8488.037760413199	72046785.02220033	0.20454853245690338	0.7954907134925333	4146.070113314448	44.16260357150593	2.2417123250668616	0.4086402266288952	0.5145184135977338	0.46458923512747874	0.4868980169971671	0.00024119225499555794	0.022643592522366775	0.4460875683369292	0.14285714285714285	7.0	8488.036002417452	72046755.17833483	453357846.0	551.0	3218.920679886686	26.47695012202259	2.0730812819302353	0.44298866855524077	0.5428470254957507	0.5042492917847026	0.5212464589235127	0.0003106631381905324	0.037768700525980727	0.48237375384958625	0.3333333333333333	3.0	8020.090258137114	64321847.74866583	3218.921388101983	26.476956140238062	2.0730812824902203	0.44298866855524077	0.5428470254957507	0.5042492917847026	0.5212464589235127	0.0003106630698395663	0.03776869194115033	0.4823737537192864	0.3333333333333333	3.0	8020.091260275052	64321863.82314028	0.15874546378782656	0.8412960258686139	3218.9210339943343	26.476953131561395	2.0730812822103117	0.44298866855524077	0.5428470254957507	0.5042492917847026	0.5212464589235127	0.0003106631040150456	0.03776869623295013	0.4823737537844168	0.3333333333333333	3.0	8020.090759195068	64321855.78572612	7		COMPLETE
